{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Image Shape: (28, 28, 1)\n",
      "\n",
      "Training Set:   55000 samples\n",
      "Validation Set: 5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)\n",
    "X_train, y_train           = mnist.train.images, mnist.train.labels\n",
    "X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test             = mnist.test.images, mnist.test.labels\n",
    "\n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_validation) == len(y_validation))\n",
    "assert(len(X_test) == len(y_test))\n",
    "\n",
    "print()\n",
    "print(\"Image Shape: {}\".format(X_train[0].shape))\n",
    "print()\n",
    "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
    "print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
    "print(\"Test Set:       {} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Pad images with 0s\n",
    "X_train      = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_validation = np.pad(X_validation, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test       = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(X_train[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB6CAYAAAB5sueeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a8d0769630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):\n",
    "    # Hyper-parameters\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # Layer 1 input = 32x32x3, output = 28x28x108\n",
    "    w_conv1 = tf.Variable(tf.truncated_normal(shape=(5,5,1,108), mean = mu, stddev = sigma))\n",
    "    b_conv1 = tf.Variable(tf.zeros([108]))\n",
    "    \n",
    "    conv1 = tf.nn.conv2d(x, w_conv1, strides=[1,1,1,1], padding='VALID') + b_conv1\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    \n",
    "    # max_pooling on layer 1 input 28x28x108, output = 14x14x108\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "    \n",
    "    # Layer 2 input 14x14x108, output = 10x10x108\n",
    "    w_conv2 = tf.Variable(tf.truncated_normal(shape=(5,5,108,108), mean = mu, stddev = sigma))\n",
    "    b_conv2 = tf.Variable(tf.zeros([108]))\n",
    "    \n",
    "    conv2 = tf.nn.conv2d(conv1, w_conv2, strides=[1,1,1,1], padding='VALID') + b_conv2\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    \n",
    "    # max_pooling on layer 1 input 10x10x108, output = 5x5x108\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "    \n",
    "    # flatten the layer so that it could be connected to fully connected layer\n",
    "    fc0 = flatten(conv2)\n",
    "    \n",
    "    # Fully-connected Layer output is 100\n",
    "    w_fc1 = tf.Variable(tf.truncated_normal(shape=(5*5*108, 100), mean = mu, stddev = sigma))\n",
    "    b_fc1 = tf.Variable(tf.zeros([100]))\n",
    "    \n",
    "    fc1 = tf.add(tf.matmul(fc0, w_fc1), b_fc1)\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    # Fully-connected Layer 2\n",
    "    w_fc2 = tf.Variable(tf.truncated_normal(shape=(100, 100), mean = mu, stddev = sigma))\n",
    "    b_fc2 = tf.Variable(tf.zeros([100]))\n",
    "    \n",
    "    fc2 = tf.add(tf.matmul(fc1, w_fc2), b_fc2)\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    \n",
    "    # Sigmoid\n",
    "    w_logits = tf.Variable(tf.truncated_normal(shape=(100, 43), mean = mu, stddev = sigma))\n",
    "    b_logits = tf.Variable(tf.zeros([43]))\n",
    "                           \n",
    "    logits = tf.add(tf.matmul(fc2, w_logits), b_logits)\n",
    "                           \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 10)\n",
    "\n",
    "num_labels = 10\n",
    "sparse_labels = tf.reshape(y, [-1, 1])\n",
    "derived_size = tf.shape(sparse_labels)[0]\n",
    "indices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])\n",
    "concated = tf.concat(1, [indices, sparse_labels])\n",
    "outshape = tf.concat(0, [tf.reshape(derived_size, [1]), tf.reshape(num_labels, [1])])\n",
    "one_hot_y = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, 'lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
